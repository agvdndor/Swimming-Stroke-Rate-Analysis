{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvirtualenvbea9a94442cd49a38f8a0c2c03c4e380",
   "display_name": "Python 3.6.9 64-bit ('venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path as osp\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# root path of project\n",
    "from os import path as osp\n",
    "import sys\n",
    "\n",
    "# get root directory\n",
    "import re\n",
    "reg = '^.*/AquaPose'\n",
    "project_root = re.findall(reg, osp.dirname(osp.abspath(sys.argv[0])))[0]\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from lib.dataset.PoseDataset import PoseDataset\n",
    "from lib.dataset.custom_transforms import DictToTensor\n",
    "from lib.models.keypoint_rcnn import get_resnet50_pretrained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_4_box_and_key_predictor.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_4_epoch.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_4_finally_fixed.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_4_finally_fixed_interrupted.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_4_only_box.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_breaststroke_epoch0', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_breaststroke_epoch0.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weights_only_box.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/weigths_corrected_4_box_and_predictor.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/_15-03-2020-17-59_epoch0.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/_15-03-2020-18-06_epoch0-10.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/_15-03-2020-18-06_epoch1-10.wth', '/mnt/c/Users/Vande/OneDrive - ugentbe/Ingenieurswetenschappen/_master/thesis/AquaPose/weights/_15-03-2020-18-06_epoch2-10.wth']\n"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "model = get_resnet50_pretrained_model()\n",
    "weight_dir = osp.join(project_root, 'weights')\n",
    "\n",
    "weight_files = glob(osp.join(weight_dir,'*'))\n",
    "print(weight_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(weight_files[-1]))\n",
    "\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_keypoints = {\n",
    "            '0': \"Nose\",\n",
    "            '1': \"left_eye\",\n",
    "            '2': \"right_eye\",\n",
    "            '3': \"left_ear\",\n",
    "            '4': \"right_ear\",\n",
    "            '5': \"Shoulder_Close\",\n",
    "            '6': \"Shoulder_Far\",\n",
    "            '7': \"Elbow_Close\",\n",
    "            '8': \"Elbow_Far\",\n",
    "            '9': \"Wrist_Close\",\n",
    "            '10': \"Wrist_Far\",\n",
    "            '11': \"Hip_Close\",\n",
    "            '12': \"Hip_Far\",\n",
    "            '13': \"Knee_Close\",\n",
    "            '14': \"Knee_Far\",\n",
    "            '15': \"Ankle_Close\",\n",
    "            '16': \"Ankle_Far\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dir = osp.join(project_root, 'demo_data')\n",
    "image_files = glob(osp.join(demo_dir, '*'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread(image_files[0])\n",
    "image_tensor = transforms.ToTensor()(image)\n",
    "model.eval()\n",
    "prediction = model([image_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}