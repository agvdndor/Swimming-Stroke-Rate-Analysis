{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvirtualenvbea9a94442cd49a38f8a0c2c03c4e380",
   "display_name": "Python 3.6.9 64-bit ('venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path as osp\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import rmsd\n",
    "# torch imports\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# root path of project\n",
    "from os import path as osp\n",
    "import sys\n",
    "\n",
    "# get root directory\n",
    "import re\n",
    "reg = '^.*/AquaPose'\n",
    "project_root = re.findall(reg, osp.dirname(osp.abspath(sys.argv[0])))[0]\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from lib.dataset.PoseDataset import PoseDataset\n",
    "\n",
    "from lib.models.keypoint_rcnn import get_resnet50_pretrained_model\n",
    "\n",
    "# utils\n",
    "from lib.utils.slack_notifications import slack_message\n",
    "from lib.utils.select_gpu import select_best_gpu\n",
    "\n",
    "# references import\n",
    "# source: https://github.com/pytorch/vision/tree/master/references/detection\n",
    "from references.engine import train_one_epoch, evaluate\n",
    "from references.utils import collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy_image(img_tensor):\n",
    "    return img_tensor.permute(1,2,0).detach().numpy()\n",
    "\n",
    "def get_max_prediction(prediction):\n",
    "    keypoints_scores = prediction[0]['keypoints_scores']\n",
    "    boxes = prediction[0]['boxes']\n",
    "    labels = prediction[0]['labels']\n",
    "    scores = prediction[0]['scores']\n",
    "    keypoints = prediction[0]['keypoints']\n",
    "\n",
    "    max_score = 0\n",
    "    max_box = []\n",
    "    for idx, box in enumerate(boxes):\n",
    "        if scores[idx].item() > max_score:\n",
    "            print(labels[idx].data.numpy())\n",
    "            max_score = scores[idx].item()\n",
    "            max_box = box\n",
    "            max_keypoints = keypoints[idx] \n",
    "            max_keypoints_scores = keypoints_scores[idx]\n",
    "    \n",
    "    return max_box.detach().numpy(), max_keypoints.detach().numpy(), max_keypoints_scores.detach().numpy()\n",
    "\n",
    "\n",
    "def plot_image_with_kps(img_tensor, kps_list, color_list= ['b', 'r', 'g']):\n",
    "    # plot positive prediction\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(tensor_to_numpy_image(img_tensor))\n",
    "    for kps, clr in zip(kps_list, color_list):\n",
    "        ax.scatter(np.array(kps)[:,0],np.array(kps)[:,1], s=10, marker='.', c=clr)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset to get a set of poses to match to\n",
    "ref_dataset = PoseDataset([osp.join(project_root,'data/vzf/freestyle/freestyle_1'), osp.join(project_root,'data/vzf/freestyle/freestyle_3')], train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get model and select weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dir = osp.join(project_root, 'weights')\n",
    "weight_files = glob(osp.join(weight_dir,'*'))\n",
    "model = get_resnet50_pretrained_model()\n",
    "#print(weight_files)\n",
    "model.load_state_dict(torch.load(weight_files[-1], map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show prediction + Groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset \n",
    "test_dataset = PoseDataset([osp.join(project_root,'data/vzf/freestyle/freestyle_2')], train=False)\n",
    "\n",
    "# get prediction\n",
    "test_id = 3\n",
    "test_img, test_target = test_dataset[test_id]\n",
    "model.eval()\n",
    "prediction = model([test_img])\n",
    "\n",
    "# get poses pred and GT\n",
    "test_pred_box, test_pred_kp, test_pred_scores = get_max_prediction(prediction)\n",
    "test_gt_kp = test_target['keypoints'][0].detach().numpy()\n",
    "# set all visible\n",
    "test_gt_kp_all_vis = [[kp[0], kp[1], 1] for kp in test_gt_kp]\n",
    "\n",
    "# plot groundtruth\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(tensor_to_numpy_image(test_img))\n",
    "ax.scatter(np.array(test_gt_kp)[:,0],np.array(test_gt_kp)[:,1], s=10, marker='.', c='b')\n",
    "\n",
    "# plot prediction\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(tensor_to_numpy_image(test_img))\n",
    "ax.scatter(np.array(test_pred_kp)[:,0],np.array(test_pred_kp)[:,1], s=10, marker='.', c='r')\n",
    "\n",
    "# plot positive prediction\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(tensor_to_numpy_image(test_img))\n",
    "#print(test_pred_scores)\n",
    "filter_inds = np.argwhere(test_pred_scores > 0).flatten()\n",
    "test_pred_kp_ftrd = test_pred_kp[filter_inds]\n",
    "ax.scatter(np.array(test_pred_kp_ftrd)[:,0],np.array(test_pred_kp_ftrd)[:,1], s=10, marker='.', c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occluded=True will only use occluded gt points\n",
    "# side = right/left will only use those keypoints\n",
    "def filter_kps(pred_kps, ref_kps, scores, min_score=0, occluded=True, side = None):\n",
    "    # merge all head keypoints into 'head'\n",
    "    pred_kps = pred_kps[4:]\n",
    "    ref_kps = ref_kps[4:]\n",
    "    scores = scores[4:]\n",
    "\n",
    "    filter_ind = np.argwhere(scores > min_score).flatten()\n",
    "\n",
    "    if not occluded:\n",
    "        not_occluded = np.argwhere(ref_kps[:,2] > 0).flatten()\n",
    "        filter_ind = np.intersect1d(filter_ind, not_occluded)\n",
    "\n",
    "    if side == 'left':\n",
    "        left_ind = [0, 1 ,3 ,5 ,7 ,9, 11, 13, 15]\n",
    "        filter_ind = np.intersect1d(filter_ind, left_ind)\n",
    "    elif side == 'right':\n",
    "        right_ind = [0, 2, 4, 6, 8, 10, 12, 14, 16]\n",
    "        filter_ind = np.intersect1d(filter_ind, right_ind)\n",
    "\n",
    "    pred_kps_ftrd = pred_kps[filter_ind]\n",
    "    ref_kps_ftrd = ref_kps[filter_ind]\n",
    "    scores_ftrd = scores[filter_ind]\n",
    "\n",
    "    return pred_kps_ftrd, ref_kps_ftrd, scores_ftrd\n",
    "\n",
    "def do_kabsch_transform(pred_kps, ref_kps):\n",
    "    # this only needs x,y value, no need for augmented matrix\n",
    "    P = np.array([kp[:2] for kp in pred_kps])\n",
    "    Q = np.array([kp[:2] for kp in ref_kps])\n",
    "\n",
    "    QC = rmsd.centroid(Q)\n",
    "    Q = Q - QC\n",
    "    P = P - rmsd.centroid(P)\n",
    "    P = rmsd.kabsch_rotate(P, Q) + QC\n",
    "\n",
    "    return P\n",
    "\n",
    "def get_affine_tf(pred_kps, ref_kps):\n",
    "    # make sure the visibility flag is 1 always (necessary for tf)\n",
    "    ref_kps_vis = [[kp[0], kp[1], 1] for kp in ref_kps]\n",
    "\n",
    "    A, res, rank, s = np.linalg.lstsq(pred_kps, ref_kps_vis)\n",
    "    return A\n",
    "\n",
    "def warp_kp(kps, tf_mat):\n",
    "    return np.dot(kps, tf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test by warping the prediction to its own ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "test_pred_kp_ftrd, test_gt_kp_ftrd, test_pred_scores_ftrd = filter_kps(test_pred_kp, test_gt_kp, test_pred_scores, min_score=0, occluded=False, side='')\n",
    "\n",
    "# get transformation\n",
    "tf_matrix = get_affine_tf(test_pred_kp_ftrd, test_gt_kp_ftrd)\n",
    "kabsch_kp = do_kabsch_transform(test_pred_kp_ftrd, test_gt_kp_ftrd)\n",
    "\n",
    "print('kabsch: {}'.format(kabsch_kp))\n",
    "# warp pose to its own gt\n",
    "test_pred_kps_warped = warp_kp(test_pred_kp_ftrd, tf_matrix)\n",
    "print('affine: {}'.format(test_pred_kps_warped))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display prediction on og image + gt and warped on matched img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot positive prediction\n",
    "plot_image_with_kps(test_img, [test_pred_kp_ftrd], ['g'])\n",
    "plot_image_with_kps(test_img, [test_gt_kp_ftrd, test_pred_kps_warped])\n",
    "plot_image_with_kps(test_img, [test_gt_kp_ftrd, kabsch_kp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def calc_dist(warped_kps, ref_kps, scores, bbox):\n",
    "\n",
    "    bbox_area = (abs(bbox[2]-bbox[0]) * abs(bbox[3] -bbox[1]))\n",
    "\n",
    "    dist = 0\n",
    "    for warped_kp, ref_kp, score in zip(warped_kps, ref_kps, scores):\n",
    "        dist += sqrt((warped_kp[0]-ref_kp[0])**2 + (warped_kp[1] - ref_kp[1])**2)\n",
    "    \n",
    "    # large bboxes lead to larger distances\n",
    "    dist /= bbox_area\n",
    "\n",
    "    # more keypoints -> more distances + harder to transform -> scale superlinear\n",
    "    dist /= len(warped_kps)**1.3\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose image to find anchor for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 8\n",
    "test_img, test_target = test_dataset[test_id]\n",
    "model.eval()\n",
    "prediction = model([test_img])\n",
    "\n",
    "# get poses pred and GT\n",
    "test_pred_box, test_pred_kp, test_pred_scores = get_max_prediction(prediction)\n",
    "\n",
    "\n",
    "# plot prediction\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(tensor_to_numpy_image(test_img))\n",
    "ax.scatter(np.array(test_pred_kp)[:,0],np.array(test_pred_kp)[:,1], s=10, marker='.', c='r')\n",
    "\n",
    "# plot positive prediction\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(tensor_to_numpy_image(test_img))\n",
    "#print(test_pred_scores)\n",
    "filter_inds = np.argwhere(test_pred_scores > 0).flatten()\n",
    "test_pred_kp_ftrd = test_pred_kp[filter_inds]\n",
    "ax.scatter(np.array(test_pred_kp_ftrd)[:,0],np.array(test_pred_kp_ftrd)[:,1], s=10, marker='.', c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search through entire database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "dists_kabsch = []\n",
    "for idx, (test_img, test_target) in enumerate(ref_dataset):\n",
    "    print('database sample: {}'.format(idx))\n",
    "\n",
    "    test_gt_kp = test_target['keypoints'][0].detach().numpy()\n",
    "    test_gt_bbox = test_target['boxes'][0].detach().numpy()\n",
    "    # set all visible\n",
    "    test_gt_kp_all_vis = [[kp[0], kp[1], 1] for kp in test_gt_kp]\n",
    "\n",
    "    # filter\n",
    "    test_pred_kp_ftrd, test_gt_kp_ftrd, test_pred_scores_ftrd = filter_kps(test_pred_kp, test_gt_kp, test_pred_scores, min_score=0, occluded=False, side='')\n",
    "\n",
    "    # get transformation\n",
    "    tf_matrix = get_affine_tf(test_pred_kp_ftrd, test_gt_kp_ftrd)\n",
    "    kabsch_kp = do_kabsch_transform(test_pred_kp_ftrd, test_gt_kp_ftrd)\n",
    "    \n",
    "    # warp pose to its own gt\n",
    "    test_pred_kps_warped = warp_kp(test_pred_kp_ftrd, tf_matrix)\n",
    "\n",
    "    # calculate distance\n",
    "    dist = calc_dist(test_pred_kps_warped, test_gt_kp_ftrd, test_pred_scores_ftrd, test_gt_bbox)\n",
    "    dist_kabsch = calc_dist(kabsch_kp, test_gt_kp_ftrd, test_pred_scores_ftrd, test_gt_bbox)\n",
    "\n",
    "    dists += [dist]\n",
    "    dists_kabsch += [dist_kabsch]\n",
    "\n",
    "    print('distance: {}'.format(dist)) \n",
    "    print('kabsch distance: {}'.format(dist_kabsch))\n",
    "\n",
    "    #plot_image_with_kps(test_img, [test_gt_kp_ftrd, test_pred_kps_warped])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's plot the least distance neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get closest matches\n",
    "num_neighbors = 5\n",
    "least_ind = np.argsort(dists)[:num_neighbors]\n",
    "least_ind_kabsch = np.argsort(dists_kabsch)[:num_neighbors]\n",
    "print(least_ind_kabsch)\n",
    "\n",
    "for ind, ind_kabsch in zip(least_ind, least_ind_kabsch):\n",
    "    test_img, test_target = ref_dataset[ind_kabsch]\n",
    "    print('database sample: {}'.format(ind))\n",
    "\n",
    "    test_gt_kp = test_target['keypoints'][0].detach().numpy()\n",
    "    test_gt_bbox = test_target['boxes'][0].detach().numpy()\n",
    "    # set all visible\n",
    "    test_gt_kp_all_vis = [[kp[0], kp[1], 1] for kp in test_gt_kp]\n",
    "\n",
    "    # filter\n",
    "    test_pred_kp_ftrd, test_gt_kp_ftrd, test_pred_scores_ftrd = filter_kps(test_pred_kp, test_gt_kp, test_pred_scores, min_score=0, occluded=False, side='')\n",
    "\n",
    "    # get transformation\n",
    "    tf_matrix = get_affine_tf(test_pred_kp_ftrd, test_gt_kp_ftrd)\n",
    "    kabsch_kp = do_kabsch_transform(test_pred_kp_ftrd, test_gt_kp_ftrd)\n",
    "\n",
    "    # warp pose to its own gt\n",
    "    test_pred_kps_warped = warp_kp(test_pred_kp_ftrd, tf_matrix)\n",
    "\n",
    "    # calculate distance\n",
    "    #dist = calc_dist(test_pred_kps_warped, test_gt_kp_ftrd, test_pred_scores_ftrd, test_gt_bbox)\n",
    "    dist_kabsch = calc_dist(kabsch_kp, test_gt_kp_ftrd, test_pred_scores_ftrd, test_gt_bbox)\n",
    "\n",
    "    #print('distance: {}'.format(dist)) \n",
    "    print('kabsch distance: {}'.format(dist_kabsch))\n",
    "\n",
    "    #plot_image_with_kps(test_img, [test_gt_kp_ftrd, test_pred_kps_warped])\n",
    "    plot_image_with_kps(test_img, [test_gt_kp_ftrd, kabsch_kp], ['k','w'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}