{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path as osp\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "# torch imports\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# root path of project\n",
    "from os import path as osp\n",
    "import sys\n",
    "\n",
    "# get root directory\n",
    "import re\n",
    "reg = '^.*/AquaPose'\n",
    "project_root = re.findall(reg, osp.dirname(osp.abspath(sys.argv[0])))[0]\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from lib.dataset.PoseDataset import PoseDataset\n",
    "from lib.dataset.CycleDataset import CycleDataset\n",
    "\n",
    "from lib.models.keypoint_rcnn import get_resnet50_pretrained_model\n",
    "\n",
    "# utils\n",
    "from lib.utils.slack_notifications import slack_message\n",
    "from lib.utils.select_gpu import select_best_gpu\n",
    "from lib.utils.rmsd import kabsch_rmsd, kabsch_rotate, kabsch_weighted_rmsd, centroid, centroid_weighted, rmsd, rmsd_weighted, kabsch\n",
    "\n",
    "# references import\n",
    "# source: https://github.com/pytorch/vision/tree/master/references/detection\n",
    "from references.engine import train_one_epoch, evaluate\n",
    "from references.utils import collate_fn\n",
    "\n",
    "from references.transforms import RandomHorizontalFlip\n",
    "\n",
    "from lib.matching.matching import *\n",
    "from lib.utils.visual_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose anchor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dataset = PoseDataset([osp.join(project_root,'data/vzf/freestyle/freestyle_1')], train=False, cache_predictions=True)\n",
    "\n",
    "anchor_ids = [x for x in range(17,81,5)]\n",
    "\n",
    "anchor_dataset = torch.utils.data.Subset(anchor_dataset, anchor_ids)\n",
    "print(len(anchor_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create for each training video a different dataset to accomodate body dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = [osp.join(project_root,'data/vzf/freestyle/freestyle_1'), osp.join(project_root,'data/vzf/freestyle/freestyle_2'), osp.join(project_root,'data/vzf/freestyle/freestyle_3'), osp.join(project_root,'data/vzf/freestyle/freestyle_4')]\n",
    "\n",
    "datasets = [PoseDataset([dir], train = False, cache_predictions=True) for dir in train_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anchor_tensor, target in anchor_dataset:\n",
    "    print(target['image_id'])\n",
    "    ref_kps = merge_head(target['keypoints'][0].detach().numpy())\n",
    "    plot_image_with_kps_skeleton(anchor_tensor, [ref_kps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create possibility to flip \n",
    "flip = RandomHorizontalFlip(1.0)\n",
    "\n",
    "# buckets[i,j] contains all ids of elements of datset[j] that have been matched to anchor i \n",
    "buckets = [[[] for x in datasets] for y in anchor_ids]\n",
    "buckets_flipped =  [[[] for x in datasets] for y in anchor_ids]\n",
    "buckets_pose_aligned = [[[] for x in datasets] for y in anchor_ids]\n",
    "\n",
    "\n",
    "# only \n",
    "t_weights = np.array([0, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0, 0, 0, 0])\n",
    "kp_weights = np.array([1.0/13] * 13)\n",
    "\n",
    "# loop over all datasets\n",
    "for ds_id, ds in enumerate(datasets):\n",
    "    for el_id, (img_tensor, target) in tqdm(enumerate(ds)):\n",
    "        \n",
    "        # get ref kps\n",
    "        ref_kps = target['keypoints'][0].detach().numpy()\n",
    "\n",
    "        # set scores all to 1\n",
    "        ref_scores = np.array([1] * len(ref_kps))\n",
    "\n",
    "        best_ind, _, flipped = get_most_similar_ind_and_scores(ref_kps, ref_scores, anchor_dataset, num=1,  filter_lr_confusion=False, occluded=True, translat_weights=T_WEIGHTS, kp_weights=KP_WEIGHTS)\n",
    "\n",
    "        # store element and whether the anchor was flipped or not\n",
    "        buckets[best_ind[0]][ds_id].append(el_id)\n",
    "        buckets_flipped[best_ind[0]][ds_id].append(flipped)\n",
    "\n",
    "        if flipped:\n",
    "             img_tensor, target = flip(img_tensor, target)\n",
    "            \n",
    "        ref_kps = np.array(merge_head(target['keypoints'][0].detach().numpy()))\n",
    "\n",
    "        translat_vec =centroid_weighted(ref_kps, t_weights)\n",
    "\n",
    "        # add aligned pose\n",
    "        buckets_pose_aligned[best_ind[0]][ds_id].append(ref_kps - translat_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for anchor_id, bucket in enumerate(buckets):\n",
    "\n",
    "    print('{}: total: {}, {}'.format(anchor_id, sum([len(ds) for ds in bucket]), [len(ds) for ds in bucket]))\n",
    "    #print('{}: {}'.format(anchor_id, [ds[:5] for ds in bucket]))\n",
    "\n",
    "print(buckets)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each image in a bucket: get stdev for each joint to avg for bucket and avg for all buckets per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(buckets_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_avg = [[[0 for z in range(0,13)] for x in datasets] for y in anchor_ids]\n",
    "bucket_stdev = [[[0 for z in range(0,13)] for x in datasets] for y in anchor_ids]\n",
    "\n",
    "# \n",
    "stdev_anchor_ds_joint= [[[0 for z in range(0,13)] for x in datasets] for y in anchor_ids]\n",
    "\n",
    "# \n",
    "stdev_ds_joint = [[0 for z in range(0,13)] for x in datasets]\n",
    "\n",
    "stdev_anchor_joint = [[0 for z in range(0,13)]for y in anchor_ids]\n",
    "\n",
    "stdev_joint = [x for x in range(0,13)]\n",
    "\n",
    "stdev_joint_per_anchor =  [x for x in range(0,13)]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(buckets_pose_aligned[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# create possibility to flip \n",
    "flip = RandomHorizontalFlip(1.0)\n",
    "\n",
    "# buckets aligned poses\n",
    "\n",
    "# weights only using hips\n",
    "t_weights = np.array([0, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0, 0, 0, 0])\n",
    "\n",
    "for ds_id, _ in enumerate(buckets[0]):\n",
    "\n",
    "    # GET STD OF EACH JOINT OVER ALL POSES PER DATASET\n",
    "    # basically buckets_pose_aligned[:,ds_id]\n",
    "    kps_aligned_ds = [row[ds_id] for row in buckets_pose_aligned]\n",
    "    \n",
    "    for joint in range(0,13):\n",
    "        kps_aligned_ds_joint = [[col[joint] for col in row] for row in kps_aligned_ds]\n",
    "\n",
    "        x_co = [[co[0] for co in row] for row in kps_aligned_ds_joint]\n",
    "        y_co = [[co[1] for co in row] for row in kps_aligned_ds_joint]\n",
    "    \n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "        # flatten\n",
    "        x_co = np.array(flatten(x_co))\n",
    "        y_co = np.array(flatten(y_co))\n",
    " \n",
    "\n",
    "        x_stdev = np.std(x_co)\n",
    "        y_dstdev = np.std(y_co)\n",
    "\n",
    "        # total stdev as distance of both\n",
    "        stdev_ds_joint[ds_id][joint] = sqrt(x_stdev**2 + y_dstdev**2)\n",
    "\n",
    "\n",
    "    # NOW GET STD FOR EACH JOINT FOR EVERY DATASET BUT INDIVIDUALLY PER POSE\n",
    "    for anchor_id, _ in enumerate(buckets):\n",
    "        kps_aligned_anchor_ds = buckets_pose_aligned[anchor_id][ds_id]\n",
    "\n",
    "        for joint in range(0,13):\n",
    "            kps_aligned_anchor_ds_joint = [col[joint] for col in kps_aligned_anchor_ds]\n",
    "            x_co = [co[0] for co in kps_aligned_anchor_ds_joint]\n",
    "            y_co = [co[1] for co in  kps_aligned_anchor_ds_joint]\n",
    "\n",
    "            # print(x_co)\n",
    "            # print(y_co)\n",
    "        \n",
    "            # flatten\n",
    "            x_co = np.array(x_co)\n",
    "            y_co = np.array(y_co)\n",
    "    \n",
    "\n",
    "            x_stdev = np.std(x_co)\n",
    "            y_dstdev = np.std(y_co)\n",
    "\n",
    "            # total stdev as distance of both\n",
    "            stdev_anchor_ds_joint[anchor_id][ds_id][joint] = sqrt(x_stdev**2 + y_dstdev**2)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over different datasets\n",
    "for anchor_id, _ in enumerate(anchor_ids):\n",
    "    weights = np.array([len(ds) for ds in buckets[anchor_id]])\n",
    "    print(weights)\n",
    "\n",
    "    for joint in range(0,13):\n",
    "        stdevs = np.array([ds[joint] for ds in stdev_anchor_ds_joint[anchor_id]])\n",
    "        #filter Nan values\n",
    "        stdevs_filtered = stdevs[~np.isnan(stdevs)]\n",
    "        print(stdevs)\n",
    "        stdev_anchor_joint[anchor_id][joint] = np.average(stdevs_filtered, weights=weights[~np.isnan(stdevs)])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}, {}'.format(len(stdev_ds_joint), len(stdev_ds_joint[0])))\n",
    "print(stdev_ds_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdev per dataset for all anchors (x-axis shows joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in stdev_ds_joint: \n",
    "    plt.plot([x for x in range(0,13)], ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stdev averaged over all datasets for each joint (x-as) every plot shows a different anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anchor in stdev_anchor_joint: \n",
    "    print(anchor)\n",
    "    plt.plot([x for x in range(0,13)], anchor)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average over all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of datasets\n",
    "weights = [sum([len(anchor[ds]) for anchor in buckets]) for ds, _ in enumerate(datasets)]\n",
    "print(weights)\n",
    "for joint in range(0,13):   \n",
    "    stdevs = np.array([ds[joint] for ds in stdev_ds_joint])\n",
    "    \n",
    "    stdev_joint[joint] = np.average(stdevs, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x in range(0,13)], stdev_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average over all buckets for per bucket stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [sum([len(ds) for ds in anchor]) for anchor in buckets]\n",
    "print(weights)\n",
    "for joint in range(0,13):\n",
    "    stdevs = [anchor[joint] for anchor in stdev_anchor_joint]\n",
    "    stdev_joint_per_anchor[joint] = np.mean(stdevs)\n",
    "\n",
    "stdev_joint_per_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x in range(0,13)], stdev_joint)\n",
    "plt.plot([x for x in range(0,13)], stdev_joint_per_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x in range(0,13)], np.array(stdev_joint)/np.array(stdev_joint_per_anchor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}