{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path as osp\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "# torch imports\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# root path of project\n",
    "from os import path as osp\n",
    "import sys\n",
    "\n",
    "# get root directory\n",
    "import re\n",
    "reg = '^.*/AquaPose'\n",
    "project_root = re.findall(reg, osp.dirname(osp.abspath(sys.argv[0])))[0]\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from lib.dataset.PoseDataset import PoseDataset\n",
    "from lib.dataset.CycleDataset import CycleDataset\n",
    "\n",
    "from lib.models.keypoint_rcnn import get_resnet50_pretrained_model\n",
    "\n",
    "# utils\n",
    "from lib.utils.slack_notifications import slack_message\n",
    "from lib.utils.select_gpu import select_best_gpu\n",
    "from lib.utils.rmsd import kabsch_rmsd, kabsch_rotate, kabsch_weighted_rmsd, centroid, centroid_weighted, rmsd, rmsd_weighted, kabsch\n",
    "\n",
    "# references import\n",
    "# source: https://github.com/pytorch/vision/tree/master/references/detection\n",
    "from references.engine import train_one_epoch, evaluate\n",
    "from references.utils import collate_fn\n",
    "\n",
    "from references.transforms import RandomHorizontalFlip\n",
    "\n",
    "from lib.matching.matching import *\n",
    "from lib.utils.visual_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = select_best_gpu(min_mem=3000) if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "print(device)\n",
    "print(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dir = osp.join(project_root, 'weights')\n",
    "weight_files = glob(osp.join(weight_dir,'*'))\n",
    "model = get_resnet50_pretrained_model()\n",
    "for i, f in enumerate(weight_files):\n",
    "    print('{}, {}'.format(i,f))\n",
    "model.load_state_dict(torch.load(weight_files[0], map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose anchor dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dataset = PoseDataset([osp.join(project_root,'data/vzf/freestyle/freestyle_1')], train=False, cache_predictions=True)\n",
    "anchor_ids = [x for x in range(17,81,1)]\n",
    "anchor_dataset = torch.utils.data.Subset(anchor_dataset, anchor_ids)\n",
    "\n",
    "#anchor_dataset = PoseDataset([osp.join(project_root,'data/vzf/freestyle/freestyle_12')], train=False, cache_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, (img,target) in enumerate(anchor_dataset):\n",
    "    ref_kps = target['keypoints'][0].detach().numpy()\n",
    "    ref_kps = merge_head(ref_kps)\n",
    "\n",
    "    print('id {}'.format(id))\n",
    "    print(target['image_id'])\n",
    "    plot_image_with_kps_skeleton(img, [ref_kps])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PoseDataset([osp.join(project_root,'data/vzf/freestyle/freestyle_5'), osp.join(project_root,'data/vzf/freestyle/freestyle_6'), osp.join(project_root,'data/vzf/freestyle/freestyle_7'), osp.join(project_root,'data/vzf/freestyle/freestyle_8'), osp.join(project_root,'data/vzf/freestyle/freestyle_9'), osp.join(project_root,'data/vzf/freestyle/freestyle_10'), osp.join(project_root,'data/vzf/freestyle/freestyle_11'), osp.join(project_root,'data/vzf/freestyle/freestyle_12'),osp.join(project_root,'data/vzf/freestyle/freestyle_13'), osp.join(project_root,'data/vzf/freestyle/freestyle_14')], cache_predictions=True)\n",
    "datasets = [test_dataset]\n",
    "print('{}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.predict_all(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide in buckets (stolen from joint_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create possibility to flip \n",
    "flip = RandomHorizontalFlip(1.0)\n",
    "\n",
    "# buckets[i,j] contains all ids of elements of datset[j] that have been matched to anchor i \n",
    "buckets = [[[] for x in datasets] for y in anchor_ids]\n",
    "ref_prob = [[] for y in anchor_ids]\n",
    "pred_prob = [[] for y in anchor_ids]\n",
    "dists = [0 for x in range(0,len(anchor_dataset))]\n",
    "buckets_flipped =  [[[] for x in datasets] for y in anchor_ids]\n",
    "buckets_pose_aligned = [[[] for x in datasets] for y in anchor_ids]\n",
    "\n",
    "\n",
    "# only \n",
    "t_weights = np.array([0, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0, 0, 0, 0])\n",
    "kp_weights = np.array([1.0/13] * 13)\n",
    "\n",
    "# loop over all datasets\n",
    "for ds_id, ds in enumerate(datasets):\n",
    "    for el_id, (img_tensor, target) in tqdm(enumerate(ds)):\n",
    "        \n",
    "        # get ref kps\n",
    "        ref_kps = target['keypoints'][0].detach().numpy()\n",
    "\n",
    "        # get pred kps\n",
    "        _, pred_kps, pred_scores = ds.predict(model, el_id)\n",
    "\n",
    "        # set scores all to 1\n",
    "        ref_scores = np.array([1] * len(ref_kps))\n",
    "\n",
    "        best_ind, scores, flipped = get_most_similar_ind_and_scores(ref_kps, ref_scores, anchor_dataset, num=len(anchor_dataset),  filter_lr_confusion=False, occluded=True, translat_weights=T_WEIGHTS, kp_weights=KP_WEIGHTS)\n",
    "\n",
    "        best_ind_pred, scores_pred , flipped_pred = get_most_similar_ind_and_scores(pred_kps, pred_scores, anchor_dataset, num=len(anchor_dataset),  filter_lr_confusion=False, occluded=True, translat_weights=T_WEIGHTS, kp_weights=KP_WEIGHTS, min_score = -float('inf'))\n",
    "\n",
    "\n",
    "        dists[abs(best_ind[0] - best_ind_pred[0])] += 1\n",
    "\n",
    "        # store element and whether the anchor was flipped or not\n",
    "        buckets[best_ind[0]][ds_id].append(el_id)\n",
    "        buckets_flipped[best_ind[0]][ds_id].append(flipped)\n",
    "\n",
    "        # get scores for each anchor for both ref and pred\n",
    "        # sort the indexes again and reorder scores accordingly\n",
    "        og_ind = np.argsort(best_ind)\n",
    "        scores = scores[og_ind]\n",
    "        ref_prob[best_ind[0]].append(scores)\n",
    "\n",
    "        og_ind = np.argsort(best_ind_pred)\n",
    "        scores_pred = scores_pred[og_ind]\n",
    "        pred_prob[best_ind_pred[0]].append(scores_pred)\n",
    "\n",
    "\n",
    "        if flipped:\n",
    "             img_tensor, target = flip(img_tensor, target)\n",
    "            \n",
    "        ref_kps = np.array(merge_head(target['keypoints'][0].detach().numpy()))\n",
    "\n",
    "        translat_vec =centroid_weighted(ref_kps, t_weights)\n",
    "\n",
    "        # add aligned pose\n",
    "        buckets_pose_aligned[best_ind[0]][ds_id].append(ref_kps - translat_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mean over all predictions and ref probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 4.0\n",
    "for anchor_id, (ref_list, pred_list) in enumerate(zip(ref_prob, pred_prob)):\n",
    "    ref_mean = np.mean(ref_list, axis=0)\n",
    "    pred_mean = np.mean(pred_list, axis=0)\n",
    "    if len(ref_list) > 1 and len(pred_list) > 1:\n",
    "        ref_mean = np.power(ref_mean, np.array([exp] * len(ref_mean)))\n",
    "        pred_mean = np.power(pred_mean, np.array([exp] * len(pred_mean)))\n",
    "        ref_mean = ref_mean/np.sum(ref_mean)\n",
    "        pred_mean = pred_mean/np.sum(pred_mean)\n",
    "        print('anchor ID: {}'.format(anchor_id))\n",
    "        plt.plot([x for x in range(0,len(anchor_dataset))], ref_mean)\n",
    "        plt.plot([x for x in range(0,len(anchor_dataset))], pred_mean)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_shifted = []\n",
    "pred_shifted = []\n",
    "\n",
    "for anchor_id, (ref_list, pred_list) in enumerate(zip(ref_prob, pred_prob)):\n",
    "    for ref, pred in zip(ref_list, pred_list):\n",
    "        ref_shifted.append(np.roll(ref,-anchor_id + 15))\n",
    "        pred_shifted.append(np.roll(pred,-anchor_id + 15))\n",
    "\n",
    "\n",
    "ref_mean = np.mean(ref_shifted, axis=0)\n",
    "pred_mean = np.mean(pred_shifted, axis=0)\n",
    "ref_mean = ref_mean/np.sum(ref_mean)\n",
    "pred_mean = pred_mean/np.sum(pred_mean)\n",
    "plt.plot([x for x in range(0,len(anchor_dataset))], ref_mean)\n",
    "plt.plot([x for x in range(0,len(anchor_dataset))], pred_mean)\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of distances from predicted match to gt match\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_norm = dists/np.sum(dists)\n",
    "plt.plot([x for x in range(0,len(anchor_dataset))], dists_norm)\n",
    "plt.xlabel('distance from true anchor pose.')\n",
    "plt.ylabel('density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}